util
메시지 교환 과정에서 json을 사용하는 이유는
경량화 되어 있고 포맷이 간단하며 파싱 자체도 빠르기 때문에
클라이언트와 서버 양쪽 모두 부담 없이 사용이 가능하기 때문이라고 판단했습니다.
즉 데이터를 전송하는데 최소한의 데이터를 전송하고자 함이라고 생각했습니다.

FileUtil

write : 매개변수로 넘어오는 file로 new FileWriter의 객체를 생성한다. FileWriter는 문자 기반 스트림으로 
데이터를 파일에 저장할 때 사용되는데 현재는 문자열 형태로 값이 넘어오기 때문에 저장이 가능하다.

read : inputStream으로 넘어온 파일의 텍스트를 읽고 buffer에 저장한 후 readLine() 메소드를 통해 
한번에 읽어온다. 물론 buffer 없이도 외부 장치와의 데이터 입출력이 가능하지만, 
하드디스크의 속도가 매우 느린점 그리고 키보드 모니터와 같은 외부장치의 속도는 시간이 더 많이 걸리는 작업임을 감안했을때 중간에 메모리 버퍼를 통해 데이터를 한데 묶어 이동시켜 성능적으로 효율을 보이고 빠른 작업을 수행할 수 있음으로 판단됩니다. 
파일에서 읽어온 값들은 character array 형식으로 변환해 return 된다.


byteUtil의 경우 
 메모리에 상주되어 있는 객체 데이터를 바이트 형태로 변환 또는 바이트 형태의 데이터를 원시 타입으로 변환해주는 역할을 합니다. 

여기서 16진수와 비트 연산자를 통해 문자열 변환을 사용한 이유는 바이트형은 8비트의 공간을, int를 예시로 들었을때 int는 32비트의 공간을 차지하는데 byte를 int로 16진수로 통해 비트를 확장하는 경우
가장 앞의 비트가 0일 경우 0으로 나머지가 채워지기 때문에 동일한 결과를 받아낼 수 있지만
가장 앞의 비트가 1일 경우 2의 보수법 처리 때문에 모든 비트가 1로 채워지게 된다.
모든 비트가 1로 채워지게 되면 기존 값과 다른 int 값이 출력되게 되기 때문에 문제가 발생하게
되는데 이를 방지하기 위해 즉 계산과정에서 생기는 부호에 대한 처리를 하기 위함으로 볼 수 있습니다.
그러나 바이트에서 다른 데이터 타입이 아닌 반대 과정에서의 16진수 계산활용은 부호가
바뀌는 일이 없기 떄문에 무의미한것으로 보입니다.


SocketWorker

소켓워커의 경우 소켓 생성과 이 소켓에 대한 inputstream과 outputstream을 생성해 
데이터를 보내거나 읽기 위한 사전 준비를 하는 역할을 해줍니다.

이때 메시지를 읽는 경우 해당 메시지의 헤더 확인을 통해 해당 값의 데이터 타입을 판별해준 뒤 해당 타입으로 값을 변환해 손실되지 않고 원본과 동일한 체크섬된 메시지를 전달 받을 수 있습니다. 

byte 단위로 변환해서 보내는 이유
클라이언트 서버가 모두 java로 구현되어 있을 경우 데이터 타입이 자동으로 맞춰지기
떄문에 상관 없지만
C++의 경우 java의 object를 이해하지 못한다. 마찬가지로 Java 역시 C++의 구조체를 이해하지 못하기 때문에
서로 byte단위로 정보를 주고 받아야 한다. 






#step2



파일 경로를 통한 생성 및 삭제 1000번 반복 과
socket설정 및 stream을 통한 서버와 클라이언트 
간의 파일 생성 및 삭제가 반복됩니다.  
쓰레드 숫자가 5의 배수로 늘어나 5,10 그리고 25까지 반복적으로 들어가게됩니다.
클라이언트측에서는 showStoreDemo 메소드를 통해 
자체적으로 통신 없이 clientTempFolder에 999개의 파일을
만들게 되고, 
클라이언트 측에서 보낸 메시지를 읽고 커맨드 명령어를 판단해 파일을 생성 또는 삭제하게 됩니다. 

스탭2 같은 경우 단일 쓰레드로 운용이되기 때문에 작업을 처리하는 쓰레드가 1개로 고정되어 있어 다른 스탭 보다 처리 시간이 상대적으로 길게 나타나는 현상을 볼 수 있었습니다.

getDispatcher를 통해 connect()하는
포트번호와 IP주소를 통해 커넥션이 되는 부분은 이해 할 수 있었다. 그러나 시스템에는 보통 많은 수의 프로세스가 동작되고 서버측에서 생성되는 소켓은 여러개가 있을텐데
시스템은 어떤 식별과정을 통해서 이 프로세스를 처리할 수 있는것일까에 대해 의문을
가졌습니다. 

보통 시스템에는 많은 수의 프로세스가 동작하는데 저희가 현재 사용 중인 TCP 프로토콜 혹은 UDP는 표준에 따라 각 소켓은 시스템이 관리하는 포트(0~65535)중 하나의 포트 번호를
사용하게 됩니다. 운영체제는 소켓들이 중복된 포트 번호를 사용하지 않도록 내부적으로
포트번호와 소켓 연결 정보를 관리할 것이고 bind() ap가 해당 소켓이 지정된 포트 번호를
사용할 것이라는 것을 운영체제에 요청할 것이고 만약 지정된 포트 번호를 다른 소켓이 사용중이라면 bind api()는 에러를 반환할 것입니다. 

이런 과정을 거쳐 서버 소켓과 포트 번호가 bind되고 나면 listen api를 통해 서버 소켓의
포트 번호로 클라이언트에서 연결 요청이 있는지 확인 하기 위해 대기 상태로 머무를 것이고 연결 요청이 확인 될 경우 데이터 송수신을 위한 새로운 소켓을 만들고 서버 소켓의 대기 큐에
쌓여 있는 첫 번째 연결 요청을 매핑시킬 것입니다. 

해당 쓰레드는 단일 쓰레드 형식으로 처리되며 쓰레드가 하나씩 처리되기 때문에
실제 처리 시간만을 지켜봐도 멀티쓰레드 형식으로 처리된 타 step보다  더 많은 시간이
투자된 것을 확인 할 수 있었습니다.


#step3
스탭3의 경우 라이브러리를 활용한 멀티 쓰레드 관리 및 executor api에 대한 이해를 목적으로 했습니다. 뒤에 있을 다른 스탭들과는 달리 여러 쓰레드를 관리할 수 있는 쓰레드 풀을
라이브러리를 활용해 관리한다는 점과 단일 스레드가 아닌 멀티 스레드 방식이 차별성을 보였습니다. executor와 쓰레드풀에 관한 내용은 뒤에서 추가적으로 더 언급하겠습니다.

#step4/5

스탭4와 5부터는 쓰레드를 담은 Queue가 등장하게 됩니다. 
Queue를 사용하게 됨으로서 프로세스에 대한 순차적인 처리가 가능해지게 됩니다.
스택일 경우 후입선출 구조를 가지기 때문에 가장 먼저 들어간 작업부터 순서대로 처리하는
FIFO 방식의 큐가 현재 작업에 더 잘 맞는 자료구조라고 생각합니다.

라우터, 쓰레드의 개수는 10개로 지정되고. 

소켓과 시퀀스 번호가 할당된 ArrayBlockingQueue의 크기를 100으로 지정해
add() , take()를 통해 queue 안에 담긴 소켓 자유롭게 사용됩니다.

특이사항으로는 ArrayBlockingQuee를 사용한 것인데 arrayBlcokingQUeue에서는
고유 락을 가지고 있기 때문에 동기화를 명시하지 않아도 동시성을 해결해줄 수 있습니다.

그리고 현재 add를 사용해 큐로 값을 넣을 경우 큐의 크기가 작아졌을때 Queue full error가 발생하는데 이를 put으로 바꿔 실험해보았습니다. 자세한 내용은 뒤에서 다시 언급하겠습니다.


#step6


스탭6에서는 쓰레드를 관리하는 pool이 만들어집니다.
서버와 클라이언트 간 통신할 수 있는 환경이 만들어지면
sharedQueue에 읽어온 데이터가 들어가게 되고 이 queue에서 값을 순차적으로 꺼내
internalQueue에 add하게 됩니다. 
pool에서 라우터(쓰레드)를 10개 만들어 take를 이용해 순차적으로
큐의 값을 꺼내옵니다. 

스탭 6의 경우 큐 관련 레이어를 두개로 나눠 운용하는 방식을 갖고 있는데 EventQueue에서 sharedQueue와 internalQueue, queue 관련된 값들을 만들어주는 처리를 전부 하고 있습니다. 큐를 두개 사용하는, 즉 레이어를 나눈 목적에 대해 확실한 목적을 갖기 위해서는 현재 eventQueue가 갖는 낮은 응집도에 대한 처리가 필요해 보입니다.



#step7

step6의 쓰레드 풀 관련 작업하는 쓰레드의 갯수를 10개로 지정해
FixedThreadPool 처럼 운용했다면
step7의 쓰레드 풀은 자체적으로 필요에 따라 쓰레드의 수를 늘리거나 줄이는 CachedThreadPool의 
역할을 합니다.

현재 step7은 두개의 레이어를 가지고 있다. 



LinkedBlockingQueue
ArrayBlockingQueue

공통점 : FIFO 순서
꺼낼때는 head 넣을 때는 tail

차이점 :

ArrayBlockingQueue
배열 형태로 저장
Array 기반이기 때문에 capacity를 최초에 지정
Queue가 꽉 찬 상태에서 put 할 경우 넣을 수 있을 때까지 block
Queue가 비어있는 경우에도 가져올 때 까지 block
싱글락 형태(producer와 consumer가 락을 공유)

LinkedBlockingQueue
linked node 형태로 저장
capacity를 지정할 수 있고 하지 않을 시 Integer.MAX_VALUE로 채워짐
collections 프레임워크에 속하기 때문에 Collection / Iterator 인터페이스를 가진다.
ArrayBlockingQueue보다 처리율(어떤 노드나 터미널에서부터 다른 터미널로 전달되는 단위,
시간당 디지털 데이터 전송으로 처리하는 양)이 높다.
더블락 형태(삽입과 삭제에 대한 락이 분리되어 있음)

하나의 데이터(객체)마다 하나의 모니터를 결합할 수 있으며,
모니터는 그것이 결합된 데이터가 동시에 두개 이상의 스레드에 의해 접근 할 수 없도록 막는 잠금 기능을 제공함
으로서 동기화를 수행

LinkedBlockingQueue의 경우 불공정성을 갖고 있기 때문에 새로운 큐에 자리가 생겼을 때 쓰레드가 새로
들어오게 된다면 자원과 시간 낭비를 절약하기 위해 앞 서 대기 중이던 쓰레드들을 무시하고 먼저
큐에 들어갈 수 있게 된다. 이렇게 계속 우선순위가 밀려 계속해서 자원을 할당 받지 못하는 쓰레드가 존재하는
starvation 상태가 생길 수 있다.
 ArrayBlockingQueue는 개발자의 필요에 따라 생성자의 인자를 통해 공정성을 설정해 이런 문제를 해결해 줄 수 있는 해결책이 될 수 있다. 



###ThreadPool


2번쨰 비교 분석의 주제는 ThreadPool입니다.
일단 쓰레드풀을 왜 사용하는지에 대한 의문으로 접근을 시작했습니다.
쓰레드풀은 병렬처리를 위해 생성하는데 스레드 풀 자체에서 지정된 스레드의 개수만큼을 미리 만들어주기 때문에 처음 생성하는 데에 대한 비용은 어쩔수 없지만 작업이 들어올시 이미 스레드가 대기 중인 상태이기 떄문에 작업을 실행하는데 있어서 딜레이가 발생하지 않는다는 장점이 있습니다. 또한 오버헤드를 줄여주고 운영체제 자체에서 메모리를 스레드에게 할당해주기 때문에 비용과 시간 관련해서 전체적인 퍼포먼스를 저하시켜줄수 있습니다.
서비스적 측면에서 다수의 사용자 요청을 수용하고 빠르게 처리하기 위해서는 쓰레드풀이 필요하다 볼 수 있습니다.

그러나 쓰레드풀에 존재하는 쓰레드의 개수가 실제 요청과 병렬처리되는 쓰레드의 숫자보다 많을 경우 일을 하지 않는 나머지 쓰레드들은 메모리만 소비할 수 있어 낭비가 발생할 수 있고 쓰레드 별로 다른 테스크 시간을 가질수 있기 때문에 병렬로 일을 처리할 경우 빨리 끝나는 스레드가 아직 일하고 있는 스레드를 기다릴수 있기 때문에 오버헤드가 발생할 수 있습니다.

그래서 쓰레드풀을 생성하는데 있어서 몇개의 쓰레드가 가장 적절한지에 대해 의문을 갖고fileserver를 executor로 구현해 실험해보았습니다.

엑시큐터의 경우 눈에 들어온 5가지 엑시큐터 서비스가 있었는데 단일 쓰레드를 생성해주는 싱글쓰레드엑시큐터와 필요에 따라 새로운 스레드를 만들어주는 캐시드스레드풀, 
미리 사용할 스레드를 지정해주고 지정된 스레드보다 많은 스레드가 사용중이라면 큐에 쌓여 대기하는 fixedThreadPool 그리고
주기적인 명령을 실행하는 scheduledThreadPool 그리고 뒤에 추가적으로 발표할 workStealingPool이 있었습니다.

newCachedThreadPool의 경우 필요한 쓰레드의 개수를 자체적으로 늘려주는 것을 확인할 수 있었습니다. 실험 결과 늘어나는 숫자는 상황마다 다른 것을 확인했습니다.
newFixedThreadPool의 경우 생성되는 스레드의 숫자를 두개로 나눴는데 newCachedThreadPool에서 최종적으로 설정하는 스레드의 숫자와 비슷한 32와 3단계일때의 22개 두가지로 실험을 진행했습니다. 그 결과 32개일 경우 1차 2차시에는 사용되지 않는 스레드가 종종 있었지만 22개일 경우보다 작업 속도가 더 빠른 것을 확인 할 수 있었습니다.

다음은 WorkStealingPool입니다. workStealingPool의 경우 ForkJoinPool을 자체적으로 가지고 있는데 이 ForkJoinPool이 여러 스레드가 있을 때 자체적으로 일을 분배해준다는 것을 확인했습니다. 작업 중인 쓰레드가 a b c가 있을 경우 b는 작업이 끝났는데 a는 현재 하는 작업 외에 다른 작업들이 밀려 있을 때 a의 작업을 b로 옮겨주는 역할을 진행합니다. 혹시나 WorkStealingPool이 작업을 하면서 분배하는 과정에서 또다른 인스턴스나 배열이 사용되나 싶어 heap을 확인해봤는데 다른 executor와 비교했을때 큰 차이가 없고 사용량의 높낮이 역시 비교적 안정적인것을 확인했습니다.

일을 균등하게 하기 때문에 쓰레드들의 작업이 끝나는 시간이 대체로 비슷한것을 확인할 수 있었습니다.


앞서 설명드린 executorService들의 메소드들을 사용할 때에 대해서 처리시간 그리고 cpu 점유율과 heap사용량을 분석해보았습니다.
아무래도 한정된 인스턴스를 jvm에서 사용하다 보니 heap의 경우 대체로 모두 비슷한 것을 확인할 수 있었고, cpu점유율의 경우 스레드를 한개 사용하는 singleThreadExecutor가 가장 낮고 cachedThreadExecutor가 스레드 수를 늘리는 과정에서 조금 더 높은 cpu를 사용하는 것을 확인했습니다. 

그래서 싱글스레드의 경우 하나로 작업을 처리할 경우 그리고 동기화와 시간 관련해 신경 쓰지 않아도 되는 상황일 경우 사용이 나쁘지 않다는 생각을 했습니다.
....



heap영역: 인스턴스와 배열이 할당되는 곳, 런타임 데이터를 저장하는 영역.  jvm이 시작될 때 생성
jvm의 heap영역은 물리적으로 nursery와 old space로 나눠진다.
nursery는 새로운 객체를 할당하기 위해 힙에 확보된 공간이다. nursery가 가득차면
young collection이라는 것을 실행하여 쓰레기를 수집한다. 
이 young collection은 nursery에 어느 정도 오래 머문 모든 객체들을 old space로 이동시켜 
nursery가 더 많은 객체를 할당할 수 있도록 조정해준다.  
               

코드 개선안
HandlerPool에서 nextRouter() 메소드를 통해 리스트의 eventRouter를 가져오는 도중 IndexOutOfBoundsException이 발생하는것을 확인했습니다. 리스트에서 큐가 제거되는 과정에서 currentIndex가 줄어들기 전 리스트의 값을 가져오려는 현상 때문에 get 메소드에
15가 들어가는 현상이 발생했습니다. indexOutofboundsException의 경우 runtimeException에 속하기 때문에 uncheckedException을 처리하기 위해 자체적으로 try catch를 통해 해당 예외가 발생할 경우 처리할 수 있도록 했고 이 예외가 발생할 경우에 대한 로직을 작성해 해결하는 과정을 가졌습니다.

외부 Queue, sharedQueue에서 꺼내오는 과정에서 interruptedException이 발생하는 것을
확인했습니다. 처음에는 take 하는 과정에서 arrayBlockingQueue 특성상 lock을 하나밖에 쓰지 않기 떄문에 쓰레드가 add하려고 접근하면서 lockInterruptibly가 lock을 사용할 수 없다고 발생시키는 예외로 생각해 LinkedBlockingQueue를 통해 take와 add를 처리한느 락을 따로 만들어주려 했으나 여전히 예외가 발생되는것을 확인했고. 이를 해결하기 위해 blockingQueue를 수정하는게 아닌 poll api를 사용하는 것으로 방향을 바꿨습니다. poll의 경우 자체적으로 interrupted 예외를 발생시키지 않고 값이 있을 경우 값을 가져오고 그렇지 않은 경우 null을 받아오기 때문에 eventInfo가 null일 경우 while문을 돌면서 poll이 값을 가져올때까지 반복하는 로직으로 구성하였습니다.
